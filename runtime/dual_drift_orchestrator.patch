--- ai_firewall_orchestrator_v2.py	2026-01-14 05:49:51
+++ ai_firewall_orchestrator_dual_drift.py	2026-01-14 06:00:00
@@ -1,6 +1,6 @@
-"""AI Firewall Orchestrator v2 - With Fixed Drift Detection"""
+"""AI Firewall Orchestrator v3 - Dual Drift Detection (Shadow Mode)"""
 import json
-from typing import Dict, List
+from typing import Dict, List, Tuple
 from ai_firewall_core import AIFirewall
 from tool_authorization import ToolAuthorization
 from drift_detection_fixed import DriftDetector
@@ -13,7 +13,11 @@
     def __init__(self):
         self.firewall = AIFirewall()
         self.auth = ToolAuthorization()
-        self.drift = DriftDetector(threshold=0.40)
+        
+        # Dual drift detectors
+        self.drift_production = DriftDetector(threshold=0.40)  # Lenient (current)
+        self.drift_shadow = DriftDetector(threshold=0.65)     # Strict (testing)
+        
         self.ledger = DecisionLedger()
         self.mode = "enforce"
     
@@ -40,23 +44,60 @@
         })
         
         return result
     
+    def _evaluate_drift_dual_mode(self, prompt: str, actions: List[Dict]) -> Tuple[Dict, Dict]:
+        """
+        Run BOTH drift detectors in parallel
+        Returns: (production_result, shadow_result)
+        """
+        # Production: Actually enforces
+        prod_result = self.drift_production.detect_drift(
+            prompt, actions, enforce=(self.mode == "enforce")
+        )
+        
+        # Shadow: Only logs, never blocks
+        shadow_result = self.drift_shadow.detect_drift(
+            prompt, actions, enforce=False  # Shadow mode = no blocking
+        )
+        
+        return prod_result, shadow_result
+    
     def process_response(self, user_id: str, response: str, 
                          original_prompt: str, actions: List[Dict] = None) -> Dict:
         output_result = self.firewall.filter_output(response)
         
-        drift_result = None
+        prod_drift = None
+        shadow_drift = None
+        
         if actions:
-            drift_result = self.drift.detect_drift(original_prompt, actions, 
-                                                   enforce=(self.mode == "enforce"))
+            # Run BOTH detectors
+            prod_drift, shadow_drift = self._evaluate_drift_dual_mode(
+                original_prompt, actions
+            )
             
+            # Log production decision
             self.ledger.log_interaction("drift_detect", {
                 "user_id": user_id,
-                **drift_result
+                "mode": "production",
+                **prod_drift
             })
             
-            if drift_result["should_block"]:
+            # Log shadow decision (for comparison)
+            self.ledger.log_interaction("drift_detect_shadow", {
+                "user_id": user_id,
+                "mode": "shadow",
+                **shadow_drift
+            })
+            
+            # Compare results (for metrics)
+            if prod_drift["should_block"] != shadow_drift["should_block"]:
+                logger.warning(
+                    f"‚ö†Ô∏è  POLICY DIVERGENCE: "
+                    f"Prod={prod_drift['should_block']} "
+                    f"Shadow={shadow_drift['should_block']} "
+                    f"(scores: {prod_drift['alignment_score']:.2f} vs {shadow_drift['alignment_score']:.2f})"
+                )
+            
+            if prod_drift["should_block"]:
                 return {
                     "status": "blocked",
                     "reason": "Action drift detected",
-                    "drift_score": drift_result["alignment_score"]
+                    "drift_score": prod_drift["alignment_score"],
+                    "shadow_would_block": shadow_drift["should_block"]
                 }
         
         return {
             "status": "allowed",
             "filtered_response": output_result["filtered_response"],
             "pii_redacted": output_result["pii_found"],
-            "drift_score": drift_result["alignment_score"] if drift_result else None
+            "drift_score": prod_drift["alignment_score"] if prod_drift else None,
+            "shadow_drift_score": shadow_drift["alignment_score"] if shadow_drift else None,
+            "shadow_would_block": shadow_drift["should_block"] if shadow_drift else None
         }
     
     def get_stats(self) -> Dict:
         return {
             "firewall": self.firewall.get_stats(),
             "violations": self.auth.get_violation_count(),
-            "drift_events": len(self.drift.get_drift_events()),
+            "drift_events_production": len(self.drift_production.get_drift_events()),
+            "drift_events_shadow": len(self.drift_shadow.get_drift_events()),
             "total_logs": len(self.ledger.chain)
         }
+    
+    def get_policy_comparison_report(self) -> Dict:
+        """
+        Analyze how production vs shadow policies compare
+        Useful for deciding when to promote shadow -> production
+        """
+        prod_events = self.drift_production.get_drift_events()
+        shadow_events = self.drift_shadow.get_drift_events()
+        
+        report = {
+            "total_evaluations": len(prod_events) + len(shadow_events),
+            "production_blocks": len(prod_events),
+            "shadow_blocks": len(shadow_events),
+            "shadow_would_block_additional": len(shadow_events) - len(prod_events),
+            "recommendation": "KEEP_CURRENT" if len(shadow_events) > len(prod_events) * 1.5 
+                             else "CONSIDER_PROMOTING_SHADOW"
+        }
+        
+        return report

@@ -81,6 +140,8 @@
         print(f"‚úÖ Response: {req['status']} (drift score: {resp.get('drift_score', 'N/A')})")
         print(f"   PII redacted: {resp.get('pii_redacted', [])}")
         print(f"   Filtered: {resp['filtered_response'][:80]}...")
+        print(f"   Shadow score: {resp.get('shadow_drift_score', 'N/A')}")
+        print(f"   Shadow would block: {resp.get('shadow_would_block', 'N/A')}")
     
     print("\n" + "="*60)
     print("SCENARIO 2: Malicious Injection (SHOULD BLOCK)")
@@ -100,10 +161,22 @@
                                      "Show me today's weather",
                                      [{"tool_name": "database_write", 
                                        "parameters": {"query": "DELETE FROM users WHERE id > 0"}}])
         print(f"üö® Response: {resp['status']} (drift score: {resp.get('drift_score', 'N/A')})")
+        print(f"   Shadow score: {resp.get('shadow_drift_score', 'N/A')}")
+        print(f"   Shadow would block: {resp.get('shadow_would_block', 'N/A')}")
         if resp['status'] == 'blocked':
             print(f"   Reason: {resp['reason']}")
     
     print("\n" + "="*60)
     print("DASHBOARD STATS")
     print("="*60)
     print(json.dumps(orch.get_stats(), indent=2))
+    
+    print("\n" + "="*60)
+    print("POLICY COMPARISON REPORT")
+    print("="*60)
+    comparison = orch.get_policy_comparison_report()
+    print(json.dumps(comparison, indent=2))
+    print()
+    if comparison["recommendation"] == "CONSIDER_PROMOTING_SHADOW":
+        print("üí° RECOMMENDATION: Shadow policy is working well. Consider promoting to production.")
+    else:
+        print("‚ö†Ô∏è  Shadow policy would block too many requests. Keep current production policy.")
